{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"python->c++.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1FCm0srbHlM9krkM39BhfVxLb8obeX13I","authorship_tag":"ABX9TyMWvCg8IlMjAE8E9hX2ix+x"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"32HkM5JZ7MZC","executionInfo":{"status":"ok","timestamp":1649581364812,"user_tz":-480,"elapsed":189996,"user":{"displayName":"britney muk","userId":"11561769268916331520"}},"outputId":"09e68ee5-79d2-405f-f755-22927c0e1fc9"},"source":["import cv2\n","import glob\n","from sklearn.neighbors import KNeighborsClassifier\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","from joblib import dump, load\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","import os\n","data=[]\n","labels=[]\n","for item in glob.glob(\"/content/drive/MyDrive/Colab Notebooks/dataset/*/*\"):# cat /dog directory\n","    img = cv2.imread(item,cv2.IMREAD_GRAYSCALE) # read images with one channel grayscale\n","    r_img= cv2.resize(img,(128,128)) # resize to 128x128\n","    r_img = np.expand_dims(r_img, axis = -1)\n","    data.append(r_img) # add resized image to dataset list\n","    label = item.split(\"/\")[6]\n","    labels.append(label) #add image label to dataset list\n","#preprocess\n","le = LabelEncoder()\n","labels = le.fit_transform(labels)\n","labels = to_categorical(labels)\n","data = np.array(data)/255 # Normalize channel between 0 to 1\n","#split test and train randomly\n","x_train, x_test, y_train, y_test = train_test_split(data,labels,test_size=0.2)\n","#train\n","net= models.Sequential(\n","                        [\n","                            layers.Conv2D(32,(3,3),strides=(1,1),activation=\"relu\",input_shape=(128,128,1)),\n","                            layers.Conv2D(32,(3,3),strides=(1,1),activation=\"relu\"),\n","                            layers.BatchNormalization(),\n","                            layers.MaxPool2D((3,3)),\n","                            layers.Conv2D(64,(5,5),strides=(1,1),activation=\"relu\"),\n","                            layers.Conv2D(64,(5,5),strides=(1,1),activation=\"relu\"),\n","                            layers.BatchNormalization(),\n","                            layers.AvgPool2D((3,3)),\n","                            layers.Dropout(0.75),\n","                            layers.Flatten(),\n","                            layers.Dense(64,activation=\"relu\"),\n","                            layers.Dense(16,activation=\"relu\"),\n","                            layers.Dense(2,activation=\"softmax\")\n","                        ]\n","                    )\n","print(net.summary())\n","net.compile(optimizer=\"SGD\", loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n","H = net.fit(x_train,y_train,batch_size=32, epochs=24, validation_data=(x_test,y_test))\n","net.save(\"CatDogNew.h5\")  # Save the model\n"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 126, 126, 32)      320       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 124, 124, 32)      9248      \n","                                                                 \n"," batch_normalization (BatchN  (None, 124, 124, 32)     128       \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 41, 41, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 37, 37, 64)        51264     \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 33, 33, 64)        102464    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 33, 33, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," average_pooling2d (AverageP  (None, 11, 11, 64)       0         \n"," ooling2D)                                                       \n","                                                                 \n"," dropout (Dropout)           (None, 11, 11, 64)        0         \n","                                                                 \n"," flatten (Flatten)           (None, 7744)              0         \n","                                                                 \n"," dense (Dense)               (None, 64)                495680    \n","                                                                 \n"," dense_1 (Dense)             (None, 16)                1040      \n","                                                                 \n"," dense_2 (Dense)             (None, 2)                 34        \n","                                                                 \n","=================================================================\n","Total params: 660,434\n","Trainable params: 660,242\n","Non-trainable params: 192\n","_________________________________________________________________\n","None\n","Epoch 1/24\n","6/6 [==============================] - 12s 339ms/step - loss: 0.9042 - accuracy: 0.5304 - val_loss: 0.6928 - val_accuracy: 0.6087\n","Epoch 2/24\n","6/6 [==============================] - 0s 77ms/step - loss: 0.7811 - accuracy: 0.6077 - val_loss: 0.6902 - val_accuracy: 0.6304\n","Epoch 3/24\n","6/6 [==============================] - 0s 76ms/step - loss: 0.7882 - accuracy: 0.6188 - val_loss: 0.6893 - val_accuracy: 0.6304\n","Epoch 4/24\n","6/6 [==============================] - 0s 78ms/step - loss: 0.7319 - accuracy: 0.5856 - val_loss: 0.6911 - val_accuracy: 0.6522\n","Epoch 5/24\n","6/6 [==============================] - 0s 78ms/step - loss: 0.7173 - accuracy: 0.6740 - val_loss: 0.6881 - val_accuracy: 0.6304\n","Epoch 6/24\n","6/6 [==============================] - 0s 76ms/step - loss: 0.6709 - accuracy: 0.6740 - val_loss: 0.6891 - val_accuracy: 0.6304\n","Epoch 7/24\n","6/6 [==============================] - 0s 79ms/step - loss: 0.6105 - accuracy: 0.7127 - val_loss: 0.6883 - val_accuracy: 0.6304\n","Epoch 8/24\n","6/6 [==============================] - 0s 75ms/step - loss: 0.6143 - accuracy: 0.6796 - val_loss: 0.6882 - val_accuracy: 0.6304\n","Epoch 9/24\n","6/6 [==============================] - 0s 75ms/step - loss: 0.5895 - accuracy: 0.6851 - val_loss: 0.6870 - val_accuracy: 0.6304\n","Epoch 10/24\n","6/6 [==============================] - 0s 77ms/step - loss: 0.5506 - accuracy: 0.7017 - val_loss: 0.6863 - val_accuracy: 0.6304\n","Epoch 11/24\n","6/6 [==============================] - 0s 80ms/step - loss: 0.5554 - accuracy: 0.7403 - val_loss: 0.6817 - val_accuracy: 0.6304\n","Epoch 12/24\n","6/6 [==============================] - 0s 78ms/step - loss: 0.5084 - accuracy: 0.7735 - val_loss: 0.6799 - val_accuracy: 0.6304\n","Epoch 13/24\n","6/6 [==============================] - 0s 76ms/step - loss: 0.5385 - accuracy: 0.7238 - val_loss: 0.6818 - val_accuracy: 0.6304\n","Epoch 14/24\n","6/6 [==============================] - 0s 77ms/step - loss: 0.5222 - accuracy: 0.7735 - val_loss: 0.6822 - val_accuracy: 0.6304\n","Epoch 15/24\n","6/6 [==============================] - 0s 78ms/step - loss: 0.4697 - accuracy: 0.8232 - val_loss: 0.6786 - val_accuracy: 0.6304\n","Epoch 16/24\n","6/6 [==============================] - 0s 77ms/step - loss: 0.5071 - accuracy: 0.7790 - val_loss: 0.6755 - val_accuracy: 0.6304\n","Epoch 17/24\n","6/6 [==============================] - 0s 78ms/step - loss: 0.4711 - accuracy: 0.7901 - val_loss: 0.6789 - val_accuracy: 0.6304\n","Epoch 18/24\n","6/6 [==============================] - 0s 78ms/step - loss: 0.4346 - accuracy: 0.7956 - val_loss: 0.6804 - val_accuracy: 0.6304\n","Epoch 19/24\n","6/6 [==============================] - 0s 77ms/step - loss: 0.4307 - accuracy: 0.8232 - val_loss: 0.6809 - val_accuracy: 0.6304\n","Epoch 20/24\n","6/6 [==============================] - 0s 77ms/step - loss: 0.4178 - accuracy: 0.8398 - val_loss: 0.6814 - val_accuracy: 0.6304\n","Epoch 21/24\n","6/6 [==============================] - 0s 78ms/step - loss: 0.3876 - accuracy: 0.8508 - val_loss: 0.6775 - val_accuracy: 0.6304\n","Epoch 22/24\n","6/6 [==============================] - 0s 76ms/step - loss: 0.4002 - accuracy: 0.8066 - val_loss: 0.6808 - val_accuracy: 0.6304\n","Epoch 23/24\n","6/6 [==============================] - 0s 77ms/step - loss: 0.3506 - accuracy: 0.8508 - val_loss: 0.6773 - val_accuracy: 0.6304\n","Epoch 24/24\n","6/6 [==============================] - 0s 76ms/step - loss: 0.3373 - accuracy: 0.8564 - val_loss: 0.6745 - val_accuracy: 0.6304\n"]}]}]}